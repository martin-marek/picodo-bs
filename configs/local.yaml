defaults:
  - default
  - _self_

batch_size_valid: 8
num_tokens_train: 100_000
num_tokens_valid: 2_048
num_eval_steps: 10
ds_path: '/Users/martin/datasets/fineweb_gpt2_2p5B.bin'
wandb_mode: 'offline'

model:
  k: 1
  L: 128

opt:
  optimizer: 'adamw'
  b1: 0.9
  t2: 100_000
  batch_size: 8
  peak_lr: null
  peak_lr_scaled: 0.001
  peak_lr_scaling: ${pow:${opt.batch_size}, 0.5}